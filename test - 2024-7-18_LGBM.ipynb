{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from tabulate import tabulate\n",
    "from hyperopt import hp, fmin, tpe, Trials, space_eval\n",
    "from sklearn.model_selection import GroupKFold, StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import cvxpy as cvx\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics.pairwise import manhattan_distances\n",
    "import quadprog\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import model_selection\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import lightgbm\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_select = lightgbm.LGBMClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate CC/ACC accuary score\n",
    "def Accuary(estimate, actual):\n",
    "  return 1 - (abs(estimate - actual) / actual)\n",
    "\n",
    "# calculate train_score, test_score\n",
    "def getScores(X_train, X_test, Y_train, nclasses):\n",
    "\n",
    "    # 使用 Platt Scaling 校准概率分数\n",
    "    model = model_select\n",
    "\n",
    "    train_scores = np.zeros((len(X_train), nclasses))\n",
    "    test_scores = np.zeros((len(X_test), nclasses))\n",
    "\n",
    "    Y_cts = np.unique(Y_train, return_counts=True)\n",
    "    nfolds = min(10, min(Y_cts[1]))\n",
    "    \n",
    "    if nfolds > 1:\n",
    "        kfold = model_selection.StratifiedKFold(n_splits=nfolds, random_state=1, shuffle=True)\n",
    "        for train_idx, test_idx in kfold.split(X_train, Y_train):\n",
    "            model.fit(X_train[train_idx], Y_train[train_idx])\n",
    "            train_scores[test_idx] = model.predict_proba(X_train[test_idx])\n",
    "\n",
    "    # 训练最终模型并预测\n",
    "    model.fit(X_train, Y_train)\n",
    "    test_scores = model.predict_proba(X_test)\n",
    "            \n",
    "    return train_scores, test_scores\n",
    "\n",
    "# EMQ function\n",
    "def EMQ(test_scores, nclasses):\n",
    "    max_it = 1000        # Max num of iterations\n",
    "    eps = 1e-1           # Small constant for stopping criterium\n",
    "\n",
    "    p_tr = [0.25, 0.25, 0.25, 0.25]\n",
    "    p_s = np.copy(p_tr)\n",
    "    p_cond_tr = np.array(test_scores)\n",
    "    p_cond_s = np.zeros(p_cond_tr.shape)\n",
    "    prob_arrays = []\n",
    "\n",
    "    for _ in range(max_it):\n",
    "        # Add Laplacian smoothing\n",
    "        # r = (p_s + alpha) / (p_tr + (alpha * nclasses))\n",
    "        r = p_s / p_tr\n",
    "        \n",
    "        p_cond_s = p_cond_tr * r\n",
    "        s = np.sum(p_cond_s, axis = 1)\n",
    "        for c in range(nclasses):\n",
    "            p_cond_s[:,c] = p_cond_s[:,c] / s\n",
    "\n",
    "        prob_arrays.append(p_cond_s)\n",
    "        p_s_old = np.copy(p_s)\n",
    "        p_s = np.sum(p_cond_s, axis = 0) / p_cond_s.shape[0]\n",
    "        if (np.sum(np.abs(p_s - p_s_old)) < eps):\n",
    "            break\n",
    "\n",
    "    return (p_s/np.sum(p_s))\n",
    "\n",
    "def GAC(train_scores, test_scores, train_labels, nclasses):\n",
    "   \n",
    "    yt_hat = np.argmax(train_scores, axis = 1)\n",
    "    y_hat = np.argmax(test_scores, axis = 1)\n",
    "    CM = metrics.confusion_matrix(train_labels, yt_hat, normalize=\"true\").T\n",
    "    p_y_hat = np.zeros(nclasses)\n",
    "    values, counts = np.unique(y_hat, return_counts=True)\n",
    "    p_y_hat[values] = counts \n",
    "    p_y_hat = p_y_hat/p_y_hat.sum()\n",
    "    \n",
    "    p_hat = cvx.Variable(CM.shape[1])\n",
    "    constraints = [p_hat >= 0, cvx.sum(p_hat) == 1.0]\n",
    "    problem = cvx.Problem(cvx.Minimize(cvx.norm(CM @ p_hat - p_y_hat)), constraints)\n",
    "    problem.solve()\n",
    "    return p_hat.value\n",
    "\n",
    "def GPAC(train_scores, test_scores, train_labels, nclasses):\n",
    "\n",
    "    CM = np.zeros((nclasses, nclasses))\n",
    "    for i in range(nclasses):\n",
    "        idx = np.where(train_labels == i)[0]\n",
    "        CM[i] = np.sum(train_scores[idx], axis=0)\n",
    "        CM[i] /= np.sum(CM[i])\n",
    "    CM = CM.T\n",
    "    p_y_hat = np.sum(test_scores, axis = 0)\n",
    "    p_y_hat = p_y_hat / np.sum(p_y_hat)\n",
    "    \n",
    "    p_hat = cvx.Variable(CM.shape[1])\n",
    "    constraints = [p_hat >= 0, cvx.sum(p_hat) == 1.0]\n",
    "    problem = cvx.Problem(cvx.Minimize(cvx.norm(CM @ p_hat - p_y_hat)), constraints)\n",
    "    problem.solve()\n",
    "    return p_hat.value\n",
    "\n",
    "def FM(train_scores, test_scores, train_labels, nclasses):\n",
    "\n",
    "    CM = np.zeros((nclasses, nclasses))\n",
    "    y_cts = np.array([np.count_nonzero(train_labels == i) for i in range(nclasses)])\n",
    "    p_yt = y_cts / train_labels.shape[0]\n",
    "    for i in range(nclasses):\n",
    "        idx = np.where(train_labels == i)[0]\n",
    "        CM[:, i] += np.sum(train_scores[idx] > p_yt, axis=0) \n",
    "    CM = CM / y_cts\n",
    "    p_y_hat = np.sum(test_scores > p_yt, axis = 0) / test_scores.shape[0]\n",
    "    \n",
    "    p_hat = cvx.Variable(CM.shape[1])\n",
    "    constraints = [p_hat >= 0, cvx.sum(p_hat) == 1.0]\n",
    "    problem = cvx.Problem(cvx.Minimize(cvx.norm(CM @ p_hat - p_y_hat)), constraints)\n",
    "    problem.solve()\n",
    "    return p_hat.value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group 1: ['12-20_culex', '01-03_arabiensis', '01-08_gambiae', '01-15_funestus']\n",
      "Group 2: ['12-21_culex', '01-04_arabiensis', '01-09_gambiae', '01-16_funestus']\n",
      "Group 3: ['12-22_culex', '01-05_arabiensis', '01-10_gambiae', '01-17_funestus']\n",
      "Group 4: ['12-23_culex', '01-06_arabiensis', '01-11_gambiae', '01-18_funestus']\n",
      "Group 5: ['12-24_culex', '01-07_arabiensis', '01-12_gambiae', '01-19_funestus']\n",
      "class\n",
      "arabiensis_female    3000\n",
      "culex_female         3000\n",
      "funestus_female      3000\n",
      "gambiae_female       3000\n",
      "Name: count, dtype: int64\n",
      "class\n",
      "gambiae_female       565\n",
      "culex_female         509\n",
      "funestus_female      370\n",
      "arabiensis_female    323\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load datasets\n",
    "train_incubator = pd.read_csv('train_incubator.csv')\n",
    "test_data = pd.read_csv('test_sf2.csv')\n",
    "\n",
    "data_file_list = [\n",
    "  ['12-20_culex', '12-21_culex', '12-22_culex', '12-23_culex', '12-24_culex'],\n",
    "  ['01-03_arabiensis', '01-04_arabiensis', '01-05_arabiensis', '01-06_arabiensis', '01-07_arabiensis'],\n",
    "  ['01-08_gambiae', '01-09_gambiae', '01-10_gambiae', '01-11_gambiae', '01-12_gambiae'],\n",
    "  ['01-15_funestus', '01-16_funestus', '01-17_funestus', '01-18_funestus', '01-19_funestus'],\n",
    "  ]\n",
    "\n",
    "temp_list = ['12-20_culex', '12-21_culex', '12-23_culex', '12-22_culex',\n",
    "             '01-07_arabiensis', '01-04_arabiensis','01-03_arabiensis','01-06_arabiensis',\n",
    "             '01-10_gambiae', '01-12_gambiae', '01-11_gambiae','01-09_gambiae',\n",
    "             '01-15_funestus', '01-19_funestus', '01-18_funestus', '01-16_funestus'\n",
    "            ]\n",
    "\n",
    "# 初始化一个空列表来存储分组结果\n",
    "groups = []\n",
    "count = 0\n",
    "# 遍历每个列（假设每列都存在数据）\n",
    "for i in range(len(data_file_list[0])):\n",
    "  # 初始化每一组\n",
    "  group = []\n",
    "  group.append(data_file_list[0][i])\n",
    "  group.append(data_file_list[1][i])\n",
    "  group.append(data_file_list[2][i])\n",
    "  group.append(data_file_list[3][i])\n",
    "\n",
    "  groups.append(group)\n",
    "  group = []\n",
    "    \n",
    "# 打印分组结果\n",
    "for idx, group in enumerate(groups):\n",
    "    print(f\"Group {idx+1}: {group}\")\n",
    "\n",
    "test_sf2 = pd.DataFrame()\n",
    "input_dir = 'grouped_data'\n",
    "\n",
    "# file_path = os.path.join(input_dir, '01-19_funestus.csv')\n",
    "# df = pd.read_csv(file_path)\n",
    "# test_sf2 = pd.concat([test_sf2, df], ignore_index=True)\n",
    "\n",
    "for file_name in temp_list:\n",
    "    file_path = os.path.join(input_dir, f'{file_name}.csv')\n",
    "    df = pd.read_csv(file_path)\n",
    "    test_sf2 = pd.concat([test_sf2, df], ignore_index=True)\n",
    "\n",
    "# Check number of examples per class\n",
    "print (train_incubator['class'].value_counts())\n",
    "print (test_sf2['class'].value_counts())\n",
    "\n",
    "# Load datasets\n",
    "# train_incubator = pd.read_csv('train_incubator.csv')\n",
    "# test_sf2 = pd.read_csv('test_sf2.csv')\n",
    "\n",
    "# # Check number of examples per class\n",
    "# print (train_incubator['class'].value_counts())\n",
    "# print (test_sf2['class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature sets\n",
    "special_features = ['temperature', 'duration', 'humidity']\n",
    "wbf_features = ['L_harmcherry_wbf_mean','L_harmcherry_wbf_stddev']\n",
    "freq_features = [f'L_harmcherry_h{i}_freq' for i in range(1,9)]\n",
    "basefreq_features = [f'L_harmcherry_h{i}_basefreq' for i in range(1,9)]\n",
    "relbasefreq_features = [f'L_harmcherry_h{i}_relbasefreq' for i in range(1,9)]\n",
    "power_features = [f'L_harmcherry_h{i}_power' for i in range(1,9)]\n",
    "relpower_features = [f'L_harmcherry_h{i}_relpower' for i in range(1,9)]\n",
    "invented_features = [f'L_harmcherry_h{i}_invented' for i in range(1,9)]\n",
    "\n",
    "feature_set = special_features+wbf_features+freq_features+basefreq_features+relbasefreq_features+power_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(train_incubator, columns=feature_set).to_numpy()\n",
    "y_train = train_incubator['class'].values \n",
    "y_train = pd.Series(y_train)\n",
    "\n",
    "X_test = pd.DataFrame(test_sf2, columns=feature_set).to_numpy()\n",
    "y_test = test_sf2['class'].values\n",
    "\n",
    "nclasses = len(train_incubator['class'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001495 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8986\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "\tAcc: 0.5161\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "arabiensis_female       0.22      0.26      0.24       323\n",
      "     culex_female       0.59      0.54      0.56       509\n",
      "  funestus_female       0.94      0.49      0.64       370\n",
      "   gambiae_female       0.51      0.66      0.58       565\n",
      "\n",
      "         accuracy                           0.52      1767\n",
      "        macro avg       0.56      0.49      0.51      1767\n",
      "     weighted avg       0.57      0.52      0.52      1767\n",
      "\n",
      "╒═════════════════════╤════════════════╤═══════════════════╤══════════════════╕\n",
      "│   arabiensis_female │   culex_female │   funestus_female │   gambiae_female │\n",
      "╞═════════════════════╪════════════════╪═══════════════════╪══════════════════╡\n",
      "│                  83 │             85 │                 0 │              155 │\n",
      "├─────────────────────┼────────────────┼───────────────────┼──────────────────┤\n",
      "│                 152 │            275 │                 5 │               77 │\n",
      "├─────────────────────┼────────────────┼───────────────────┼──────────────────┤\n",
      "│                  55 │             14 │               181 │              120 │\n",
      "├─────────────────────┼────────────────┼───────────────────┼──────────────────┤\n",
      "│                  92 │             93 │                 7 │              373 │\n",
      "╘═════════════════════╧════════════════╧═══════════════════╧══════════════════╛\n"
     ]
    }
   ],
   "source": [
    "model = model_select\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "p_labels = model.predict(X_test)\n",
    "acc = accuracy_score(y_test, p_labels)\n",
    "\n",
    "print(f\"\\tAcc: {acc:.4f}\")\n",
    "print(classification_report(y_test, p_labels, labels=np.unique(y_test)))\n",
    "\n",
    "cf = confusion_matrix(y_test, p_labels, labels=np.unique(y_train))\n",
    "print(tabulate(cf, headers=np.unique(y_train), tablefmt='fancy_grid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arabiensis CC: 0.8173374613003096\n",
      "culex CC: 0.9174852652259332\n",
      "funestus CC: 0.5216216216216216\n",
      "gambiae CC: 0.7168141592920354\n"
     ]
    }
   ],
   "source": [
    "arabiensis_CC_estimate = cf[0][0]+cf[1][0]+cf[2][0]+cf[3][0]\n",
    "arabiensis_actual = cf[0][0]+cf[0][1]+cf[0][2]+cf[0][3]\n",
    "arabiensis_CC = Accuary(arabiensis_CC_estimate, arabiensis_actual)\n",
    "print('arabiensis CC:', arabiensis_CC)\n",
    "\n",
    "culex_CC_estimate = cf[0][1]+cf[1][1]+cf[2][1]+cf[3][1]\n",
    "culex_actual = cf[1][0]+cf[1][1]+cf[1][2]+cf[1][3]\n",
    "culex_CC = Accuary(culex_CC_estimate, culex_actual)\n",
    "print('culex CC:', culex_CC)\n",
    "\n",
    "funestus_CC_estimate = cf[0][2]+cf[1][2]+cf[2][2]+cf[3][2]\n",
    "funestus_actual = cf[2][0]+cf[2][1]+cf[2][2]+cf[2][3]\n",
    "funestus_CC = Accuary(funestus_CC_estimate, funestus_actual)\n",
    "print('funestus CC:', funestus_CC)\n",
    "\n",
    "gambiae_CC_estimate = cf[0][3]+cf[1][3]+cf[2][3]+cf[3][3]\n",
    "gambiae_actual = cf[3][0]+cf[3][1]+cf[3][2]+cf[3][3]\n",
    "gambiae_CC = Accuary(gambiae_CC_estimate, gambiae_actual)\n",
    "print('gambiae CC:', gambiae_CC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arabiensis's TPR at semi_field: 0.25696594427244585\n",
      "culex's TPR at semi_field: 0.5402750491159135\n",
      "funestus's TPR at semi_field: 0.4891891891891892\n",
      "gambiae's TPR at semi_field: 0.6601769911504425\n"
     ]
    }
   ],
   "source": [
    "# class's tpr\n",
    "arabiensis_estimate_number = cf[0][0]\n",
    "culex_estimate_number = cf[1][1]\n",
    "funestus_estimate_number = cf[2][2]\n",
    "gambiae_estimate_number = cf[3][3]\n",
    "\n",
    "arabiensis_semi_tpr = arabiensis_estimate_number / arabiensis_actual\n",
    "print(\"arabiensis's TPR at semi_field:\", arabiensis_semi_tpr)\n",
    "\n",
    "culex_semi_tpr = culex_estimate_number / culex_actual\n",
    "print(\"culex's TPR at semi_field:\", culex_semi_tpr)\n",
    "\n",
    "funestus_semi_tpr = funestus_estimate_number / funestus_actual\n",
    "print(\"funestus's TPR at semi_field:\", funestus_semi_tpr)\n",
    "\n",
    "gambiae_semi_tpr = gambiae_estimate_number / gambiae_actual\n",
    "print(\"gambiae's TPR at semi_field:\", gambiae_semi_tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001043 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8981\n",
      "[LightGBM] [Info] Number of data points in the train set: 9395, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -1.379823\n",
      "[LightGBM] [Info] Start training from score -1.321889\n",
      "[LightGBM] [Info] Start training from score -1.412937\n",
      "[LightGBM] [Info] Start training from score -1.434148\n",
      "number:  2605\n",
      "\tAcc: 0.5893\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "arabiensis_female       0.44      0.42      0.43       636\n",
      "     culex_female       0.56      0.77      0.65       495\n",
      "  funestus_female       0.72      0.80      0.76       713\n",
      "   gambiae_female       0.58      0.42      0.49       761\n",
      "\n",
      "         accuracy                           0.59      2605\n",
      "        macro avg       0.58      0.60      0.58      2605\n",
      "     weighted avg       0.58      0.59      0.58      2605\n",
      "\n",
      "╒═════════════════════╤════════════════╤═══════════════════╤══════════════════╕\n",
      "│   arabiensis_female │   culex_female │   funestus_female │   gambiae_female │\n",
      "╞═════════════════════╪════════════════╪═══════════════════╪══════════════════╡\n",
      "│                 264 │            131 │               111 │              130 │\n",
      "├─────────────────────┼────────────────┼───────────────────┼──────────────────┤\n",
      "│                  67 │            379 │                10 │               39 │\n",
      "├─────────────────────┼────────────────┼───────────────────┼──────────────────┤\n",
      "│                  50 │             31 │               573 │               59 │\n",
      "├─────────────────────┼────────────────┼───────────────────┼──────────────────┤\n",
      "│                 214 │            130 │                98 │              319 │\n",
      "╘═════════════════════╧════════════════╧═══════════════════╧══════════════════╛\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001369 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8972\n",
      "[LightGBM] [Info] Number of data points in the train set: 9638, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -1.430199\n",
      "[LightGBM] [Info] Start training from score -1.406205\n",
      "[LightGBM] [Info] Start training from score -1.335126\n",
      "[LightGBM] [Info] Start training from score -1.376178\n",
      "number:  2362\n",
      "\tAcc: 0.5453\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "arabiensis_female       0.04      0.01      0.01       694\n",
      "     culex_female       0.80      0.75      0.77       638\n",
      "  funestus_female       0.85      0.82      0.83       464\n",
      "   gambiae_female       0.36      0.76      0.48       566\n",
      "\n",
      "         accuracy                           0.55      2362\n",
      "        macro avg       0.51      0.58      0.53      2362\n",
      "     weighted avg       0.48      0.55      0.49      2362\n",
      "\n",
      "╒═════════════════════╤════════════════╤═══════════════════╤══════════════════╕\n",
      "│   arabiensis_female │   culex_female │   funestus_female │   gambiae_female │\n",
      "╞═════════════════════╪════════════════╪═══════════════════╪══════════════════╡\n",
      "│                   5 │             57 │                27 │              605 │\n",
      "├─────────────────────┼────────────────┼───────────────────┼──────────────────┤\n",
      "│                  19 │            476 │                14 │              129 │\n",
      "├─────────────────────┼────────────────┼───────────────────┼──────────────────┤\n",
      "│                  34 │             11 │               379 │               40 │\n",
      "├─────────────────────┼────────────────┼───────────────────┼──────────────────┤\n",
      "│                  59 │             52 │                27 │              428 │\n",
      "╘═════════════════════╧════════════════╧═══════════════════╧══════════════════╛\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001180 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8985\n",
      "[LightGBM] [Info] Number of data points in the train set: 9961, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -1.429059\n",
      "[LightGBM] [Info] Start training from score -1.371645\n",
      "[LightGBM] [Info] Start training from score -1.410375\n",
      "[LightGBM] [Info] Start training from score -1.336649\n",
      "number:  2039\n",
      "\tAcc: 0.6057\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "arabiensis_female       0.56      0.45      0.50       614\n",
      "     culex_female       0.67      0.55      0.60       473\n",
      "  funestus_female       0.76      0.83      0.79       569\n",
      "   gambiae_female       0.43      0.59      0.49       383\n",
      "\n",
      "         accuracy                           0.61      2039\n",
      "        macro avg       0.60      0.61      0.60      2039\n",
      "     weighted avg       0.61      0.61      0.60      2039\n",
      "\n",
      "╒═════════════════════╤════════════════╤═══════════════════╤══════════════════╕\n",
      "│   arabiensis_female │   culex_female │   funestus_female │   gambiae_female │\n",
      "╞═════════════════════╪════════════════╪═══════════════════╪══════════════════╡\n",
      "│                 278 │             79 │                66 │              191 │\n",
      "├─────────────────────┼────────────────┼───────────────────┼──────────────────┤\n",
      "│                 123 │            260 │                18 │               72 │\n",
      "├─────────────────────┼────────────────┼───────────────────┼──────────────────┤\n",
      "│                  31 │             25 │               471 │               42 │\n",
      "├─────────────────────┼────────────────┼───────────────────┼──────────────────┤\n",
      "│                  68 │             23 │                66 │              226 │\n",
      "╘═════════════════════╧════════════════╧═══════════════════╧══════════════════╛\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001105 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8989\n",
      "[LightGBM] [Info] Number of data points in the train set: 10062, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -1.428724\n",
      "[LightGBM] [Info] Start training from score -1.370714\n",
      "[LightGBM] [Info] Start training from score -1.445454\n",
      "[LightGBM] [Info] Start training from score -1.306298\n",
      "number:  1938\n",
      "\tAcc: 0.6259\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "arabiensis_female       0.67      0.29      0.41       589\n",
      "     culex_female       0.55      0.83      0.66       445\n",
      "  funestus_female       0.85      0.81      0.83       629\n",
      "   gambiae_female       0.40      0.60      0.48       275\n",
      "\n",
      "         accuracy                           0.63      1938\n",
      "        macro avg       0.62      0.63      0.59      1938\n",
      "     weighted avg       0.66      0.63      0.61      1938\n",
      "\n",
      "╒═════════════════════╤════════════════╤═══════════════════╤══════════════════╕\n",
      "│   arabiensis_female │   culex_female │   funestus_female │   gambiae_female │\n",
      "╞═════════════════════╪════════════════╪═══════════════════╪══════════════════╡\n",
      "│                 172 │            229 │                50 │              138 │\n",
      "├─────────────────────┼────────────────┼───────────────────┼──────────────────┤\n",
      "│                   8 │            369 │                 1 │               67 │\n",
      "├─────────────────────┼────────────────┼───────────────────┼──────────────────┤\n",
      "│                  35 │             40 │               507 │               47 │\n",
      "├─────────────────────┼────────────────┼───────────────────┼──────────────────┤\n",
      "│                  41 │             34 │                35 │              165 │\n",
      "╘═════════════════════╧════════════════╧═══════════════════╧══════════════════╛\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001012 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8984\n",
      "[LightGBM] [Info] Number of data points in the train set: 10254, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -1.344092\n",
      "[LightGBM] [Info] Start training from score -1.494324\n",
      "[LightGBM] [Info] Start training from score -1.318980\n",
      "[LightGBM] [Info] Start training from score -1.396686\n",
      "number:  1746\n",
      "\tAcc: 0.4926\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "arabiensis_female       0.24      0.46      0.31       326\n",
      "     culex_female       0.75      0.46      0.57       699\n",
      "  funestus_female       0.57      0.67      0.62       258\n",
      "   gambiae_female       0.56      0.46      0.50       463\n",
      "\n",
      "         accuracy                           0.49      1746\n",
      "        macro avg       0.53      0.51      0.50      1746\n",
      "     weighted avg       0.57      0.49      0.51      1746\n",
      "\n",
      "╒═════════════════════╤════════════════╤═══════════════════╤══════════════════╕\n",
      "│   arabiensis_female │   culex_female │   funestus_female │   gambiae_female │\n",
      "╞═════════════════════╪════════════════╪═══════════════════╪══════════════════╡\n",
      "│                 149 │             43 │                52 │               82 │\n",
      "├─────────────────────┼────────────────┼───────────────────┼──────────────────┤\n",
      "│                 288 │            325 │                28 │               58 │\n",
      "├─────────────────────┼────────────────┼───────────────────┼──────────────────┤\n",
      "│                  49 │              7 │               173 │               29 │\n",
      "├─────────────────────┼────────────────┼───────────────────┼──────────────────┤\n",
      "│                 138 │             61 │                51 │              213 │\n",
      "╘═════════════════════╧════════════════╧═══════════════════╧══════════════════╛\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001146 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8982\n",
      "[LightGBM] [Info] Number of data points in the train set: 10690, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -1.318837\n",
      "[LightGBM] [Info] Start training from score -1.357708\n",
      "[LightGBM] [Info] Start training from score -1.401185\n",
      "[LightGBM] [Info] Start training from score -1.474037\n",
      "number:  1310\n",
      "\tAcc: 0.5939\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "arabiensis_female       0.22      0.55      0.32       141\n",
      "     culex_female       0.54      0.65      0.59       250\n",
      "  funestus_female       0.81      0.68      0.74       367\n",
      "   gambiae_female       0.82      0.52      0.64       552\n",
      "\n",
      "         accuracy                           0.59      1310\n",
      "        macro avg       0.60      0.60      0.57      1310\n",
      "     weighted avg       0.70      0.59      0.62      1310\n",
      "\n",
      "╒═════════════════════╤════════════════╤═══════════════════╤══════════════════╕\n",
      "│   arabiensis_female │   culex_female │   funestus_female │   gambiae_female │\n",
      "╞═════════════════════╪════════════════╪═══════════════════╪══════════════════╡\n",
      "│                  78 │             30 │                16 │               17 │\n",
      "├─────────────────────┼────────────────┼───────────────────┼──────────────────┤\n",
      "│                  50 │            163 │                12 │               25 │\n",
      "├─────────────────────┼────────────────┼───────────────────┼──────────────────┤\n",
      "│                  65 │             32 │               251 │               19 │\n",
      "├─────────────────────┼────────────────┼───────────────────┼──────────────────┤\n",
      "│                 159 │             76 │                31 │              286 │\n",
      "╘═════════════════════╧════════════════╧═══════════════════╧══════════════════╛\n",
      "arabiensis_lab_tpr: 0.3628891263025673\n",
      "culex_lab_tpr: 0.6679307262063899\n",
      "funestus_lab_tpr: 0.7681220999227154\n",
      "gambiae_lab_tpr: 0.5572677492768366\n"
     ]
    }
   ],
   "source": [
    "X = pd.DataFrame(train_incubator, columns=feature_set).to_numpy()\n",
    "y = train_incubator['class'].values \n",
    "\n",
    "model = model_select\n",
    "\n",
    "groups = train_incubator['sensor'].values\n",
    "group_kfold = GroupKFold(n_splits=6)\n",
    "\n",
    "arabiensis_lab_tpr = 0\n",
    "culex_lab_tpr = 0\n",
    "funestus_lab_tpr = 0\n",
    "gambiae_lab_tpr = 0\n",
    "\n",
    "for train_index_lab, test_index_lab in group_kfold.split(X, y, groups):\n",
    "  X_train_lab, y_train_lab, X_test_lab, y_test_lab = X[train_index_lab], y[train_index_lab], X[test_index_lab], y[test_index_lab]\n",
    "  model.fit(X[train_index_lab], y[train_index_lab])\n",
    "\n",
    "  p_labels_lab = model.predict(X_test_lab)\n",
    "  a_labels_lab = y_test_lab\n",
    "  acc = accuracy_score(a_labels_lab, p_labels_lab)\n",
    "  print('number: ', len(a_labels_lab))\n",
    "\n",
    "  print(\"\\tAcc: %.4f\" % acc)\n",
    "  print (classification_report(a_labels_lab, p_labels_lab, labels=np.unique(y_test_lab)))\n",
    "      \n",
    "  cf_lab = confusion_matrix(a_labels_lab, p_labels_lab, labels=np.unique(y_train_lab))\n",
    "  arabiensis_actual_lab = cf_lab[0][0]+cf_lab[0][1]+cf_lab[0][2]+cf_lab[0][3]\n",
    "  culex_actual_lab = cf_lab[1][0]+cf_lab[1][1]+cf_lab[1][2]+cf_lab[1][3]\n",
    "  funestus_actual_lab = cf_lab[2][0]+cf_lab[2][1]+cf_lab[2][2]+cf_lab[2][3]\n",
    "  gambiae_actual_lab = cf_lab[3][0]+cf_lab[3][1]+cf_lab[3][2]+cf_lab[3][3]\n",
    "  arabiensis_lab_tpr += cf_lab[0][0] / arabiensis_actual_lab\n",
    "  culex_lab_tpr += cf_lab[1][1] / culex_actual_lab\n",
    "  funestus_lab_tpr += cf_lab[2][2] / funestus_actual_lab\n",
    "  gambiae_lab_tpr += cf_lab[3][3] / gambiae_actual_lab\n",
    "\n",
    "  print(tabulate(cf_lab, headers=np.unique(y_train_lab), tablefmt='fancy_grid'))\n",
    "\n",
    "arabiensis_lab_tpr = arabiensis_lab_tpr / 6\n",
    "culex_lab_tpr = culex_lab_tpr / 6\n",
    "funestus_lab_tpr = funestus_lab_tpr / 6\n",
    "gambiae_lab_tpr = gambiae_lab_tpr / 6\n",
    "\n",
    "print('arabiensis_lab_tpr:', arabiensis_lab_tpr)\n",
    "print('culex_lab_tpr:', culex_lab_tpr)\n",
    "print('funestus_lab_tpr:', funestus_lab_tpr)\n",
    "print('gambiae_lab_tpr:', gambiae_lab_tpr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arabiensis ACC:  0.708111446850558\n",
      "culex ACC:  0.8088788671012106\n",
      "funestus ACC:  0.6368638387548138\n",
      "gambiae ACC:  0.8153325003875596\n"
     ]
    }
   ],
   "source": [
    "arabiensis_ACC_estimate = arabiensis_estimate_number / arabiensis_lab_tpr\n",
    "culex_ACC_estimate = culex_estimate_number / culex_lab_tpr\n",
    "funestus_ACC_estimate = funestus_estimate_number / funestus_lab_tpr\n",
    "gambiae_ACC_estimate = gambiae_estimate_number / gambiae_lab_tpr\n",
    "\n",
    "arabiensis_ACC = Accuary(arabiensis_ACC_estimate, arabiensis_actual)\n",
    "culex_ACC = Accuary(culex_ACC_estimate, culex_actual)\n",
    "funestus_ACC = Accuary(funestus_ACC_estimate, funestus_actual)\n",
    "gambiae_ACC = Accuary(gambiae_ACC_estimate, gambiae_actual)\n",
    "\n",
    "print('arabiensis ACC: ', arabiensis_ACC)\n",
    "print('culex ACC: ', culex_ACC)\n",
    "print('funestus ACC: ', funestus_ACC)\n",
    "print('gambiae ACC: ', gambiae_ACC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001167 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8982\n",
      "[LightGBM] [Info] Number of data points in the train set: 10800, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001269 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8983\n",
      "[LightGBM] [Info] Number of data points in the train set: 10800, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001105 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8984\n",
      "[LightGBM] [Info] Number of data points in the train set: 10800, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001097 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8982\n",
      "[LightGBM] [Info] Number of data points in the train set: 10800, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000801 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8983\n",
      "[LightGBM] [Info] Number of data points in the train set: 10800, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001023 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8984\n",
      "[LightGBM] [Info] Number of data points in the train set: 10800, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001010 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8983\n",
      "[LightGBM] [Info] Number of data points in the train set: 10800, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001167 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8984\n",
      "[LightGBM] [Info] Number of data points in the train set: 10800, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000956 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8984\n",
      "[LightGBM] [Info] Number of data points in the train set: 10800, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001093 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8982\n",
      "[LightGBM] [Info] Number of data points in the train set: 10800, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001256 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8986\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "arabiensis PCC:  0.5265804154314662\n",
      "culex PCC:  0.896649375723189\n",
      "funestus PCC:  0.4577855794488723\n",
      "gambiae PCC:  0.8224596857607485\n"
     ]
    }
   ],
   "source": [
    "train_scores, test_scores = getScores(X_train, X_test, y_train, nclasses)\n",
    "estimated_counts = np.mean(test_scores, axis=0) * len(test_scores)\n",
    "\n",
    "arabiensis_PCC_estimate = estimated_counts[0]\n",
    "culex_PCC_estimate = estimated_counts[1]\n",
    "funestus_PCC_estimate = estimated_counts[2]\n",
    "gambiae_PCC_estimate = estimated_counts[3]\n",
    "\n",
    "arabiensis_PCC = Accuary(arabiensis_PCC_estimate, arabiensis_actual)\n",
    "culex_PCC = Accuary(culex_PCC_estimate, culex_actual)\n",
    "funestus_PCC = Accuary(funestus_PCC_estimate, funestus_actual)\n",
    "gambiae_PCC = Accuary(gambiae_PCC_estimate, gambiae_actual)\n",
    "\n",
    "print('arabiensis PCC: ', arabiensis_PCC)\n",
    "print('culex PCC: ', culex_PCC)\n",
    "print('funestus PCC: ', funestus_PCC)\n",
    "print('gambiae PCC: ', gambiae_PCC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arabiensis EMQ:  0.6448033795416221\n",
      "culex EMQ:  0.7986932911913616\n",
      "funestus EMQ:  0.20803845013522482\n",
      "gambiae EMQ:  0.5030754339371541\n"
     ]
    }
   ],
   "source": [
    "res = EMQ(test_scores, nclasses)\n",
    "\n",
    "arabiensis_EMQ_estimate = res[0] * len(test_scores)\n",
    "culex_EMQ_estimate = res[1] * len(test_scores)\n",
    "funestus_EMQ_estimate = res[2] * len(test_scores)\n",
    "gambiae_EMQ_estimate = res[3] * len(test_scores)\n",
    "\n",
    "arabiensis_EMQ = Accuary(arabiensis_EMQ_estimate, arabiensis_actual)\n",
    "culex_EMQ = Accuary(culex_EMQ_estimate, culex_actual)\n",
    "funestus_EMQ = Accuary(funestus_EMQ_estimate, funestus_actual)\n",
    "gambiae_EMQ = Accuary(gambiae_EMQ_estimate, gambiae_actual)\n",
    "\n",
    "print('arabiensis EMQ: ', arabiensis_EMQ)\n",
    "print('culex EMQ: ', culex_EMQ)\n",
    "print('funestus EMQ: ', funestus_EMQ)\n",
    "print('gambiae EMQ: ', gambiae_EMQ)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp9991",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
